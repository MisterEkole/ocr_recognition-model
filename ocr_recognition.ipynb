{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x28495d8c7c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "tar= tarfile.open('D:/Dev Projects/AI_Projects/ocr_recognition_model/EnglishFnt.tgz')\n",
    "tar.extractall('./EnglishFnt')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Transforms\n",
    "\n",
    "dataset= torchvision.datasets.ImageFolder(\n",
    "    root= './EnglishFnt/English/Fnt',\n",
    "    transform= transforms.Compose(\n",
    "        [\n",
    "        transforms.Resize((48,48)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create fxn to split dataset\n",
    "\n",
    "def split_data(dts, batch_size, test_split=0.3):\n",
    "    shuffle_dataset= True\n",
    "    random_seed= 42\n",
    "    dataset_size=len(dts)\n",
    "    \n",
    "    indices= list(range(dataset_size))\n",
    "    split=int(np.floor(test_split*dataset_size))\n",
    "    \n",
    "    if shuffle_dataset:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "    train_indices, test_indices=indices[split:], indices[:split]\n",
    "    \n",
    "    test_size=len(test_indices)\n",
    "    indices= list(range(test_size))\n",
    "    split=int(np.floor(0.5*test_size))\n",
    "    \n",
    "    if shuffle_dataset:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    val_indices, test_indices= indices[split:], indices[:split]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #data samplers and loaders\n",
    "    train_sampler=torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    test_sampler= torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "    val_sampler= torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "    \n",
    "    train_loader=torch.utils.data.DataLoader(dts,batch_size, sampler=train_sampler)\n",
    "    \n",
    "    val_loader=torch.utils.data.DataLoader(dts, batch_size, sampler=val_sampler)\n",
    "    \n",
    "    test_loader= torch.utils.data.DataLoader(dts,batch_size, sampler=test_sampler)\n",
    "    \n",
    "    return train_loader, test_loader, val_loader\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=36\n",
    "train_loader,test_loader,val_loader= split_data(dataset, batch_size,test_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definint the neural network\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,16,3)\n",
    "        self.conv2=nn.Conv2d(16,32,3)\n",
    "        self.conv3=nn.Conv2d(32,64,3)\n",
    "        self.fc1=nn.Linear(64*9*9,62)\n",
    "        \n",
    "        self.max_pool=nn.MaxPool2d(2,2, ceil_mode=True)\n",
    "        self.dropout= nn.Dropout(0.2)\n",
    "        \n",
    "        self.conv_bn1=nn.BatchNorm2d(48,3)\n",
    "        self.conv_bn2= nn.BatchNorm2d(16)\n",
    "        self.conv_bn3= nn.BatchNorm2d(32)\n",
    "        self.conv_bn4= nn.BatchNorm2d(64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=F.relu(self.conv1(x))\n",
    "        x=self.max_pool(x)\n",
    "        x=self.conv_bn2(x)\n",
    "        \n",
    "        x=F.relu(self.conv2(x))\n",
    "        \n",
    "        x=self.max_pool(x)\n",
    "        x=self.conv_bn3(x)\n",
    "        \n",
    "        \n",
    "        x=F.relu(self.conv3(x))\n",
    "        x=self.conv_bn4(x)\n",
    "        \n",
    "        x=x.view(-1,64*9*9)\n",
    "        \n",
    "        x=self.dropout(x)\n",
    "        x=self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot encoding\n",
    "\n",
    "def one_hot_encode(lables, pred_size):\n",
    "    encoded=torch.zeros(len(lables), pred_size)\n",
    "    y=0\n",
    "    for x in lables:\n",
    "        encoded[y][x]=1\n",
    "        y+=1\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the loss and optimiser\n",
    "\n",
    "class LossFxn(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, lables):\n",
    "        y=one_hot_encode(lables, len(pred[0]))\n",
    "        y=y.cpu()\n",
    "        \n",
    "        ctx.save_for_backward(y, pred)\n",
    "        loss=-y*torch.log(pred)\n",
    "        \n",
    "        loss=loss.sum()/len(lables)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    \n",
    "    def backward(ctx,grad_output):\n",
    "        y, pred=ctx.saved_tensors\n",
    "        grad_input=(-y/pred)-y\n",
    "        grad_input= grad_input/len(pred)\n",
    "        \n",
    "        return grad_input, grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss_cell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(loss_cell, self).__init__()\n",
    "        \n",
    "    def forward(self, pred, lables):\n",
    "        y=one_hot_encode(lables, len(pred[0]))\n",
    "        y=y.cpu()\n",
    "        \n",
    "        loss=-y*torch.log(pred)\n",
    "        loss=loss.sum()/len(lables)\n",
    "        \n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mittr\\AppData\\Local\\Temp/ipykernel_5136/4124712075.py:87: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred=F.softmax(pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Training accu: tensor(0.) Train Loss: 0.003452882572096221\n",
      "Epoch:  1 Val Acc:  tensor(0.) Val Loss: 0.0165542794724381\n",
      "Epoch:  1 Val Acc:  tensor(0.0139) Val Loss: 0.03333368772789553\n",
      "Epoch:  1 Val Acc:  tensor(0.0093) Val Loss: 0.04961327998810395\n",
      "Epoch:  1 Val Acc:  tensor(0.0139) Val Loss: 0.06586002487646762\n",
      "Epoch:  1 Val Acc:  tensor(0.0111) Val Loss: 0.0821609007541671\n",
      "Epoch:  1 Val Acc:  tensor(0.0139) Val Loss: 0.09756580867694811\n",
      "Epoch:  1 Val Acc:  tensor(0.0159) Val Loss: 0.11359157852346906\n",
      "Epoch:  1 Val Acc:  tensor(0.0174) Val Loss: 0.12939241721149633\n",
      "Epoch:  1 Val Acc:  tensor(0.0185) Val Loss: 0.1458010329039831\n",
      "Epoch:  1 Val Acc:  tensor(0.0194) Val Loss: 0.16197615793902612\n",
      "Epoch:  1 Val Acc:  tensor(0.0227) Val Loss: 0.17826242954558746\n",
      "Epoch:  1 Val Acc:  tensor(0.0255) Val Loss: 0.1944825531411987\n",
      "Epoch:  1 Val Acc:  tensor(0.0256) Val Loss: 0.21078388953843497\n",
      "Epoch:  1 Val Acc:  tensor(0.0238) Val Loss: 0.22700063538641985\n",
      "Epoch:  1 Val Acc:  tensor(0.0222) Val Loss: 0.24310777577157255\n",
      "Epoch:  1 Val Acc:  tensor(0.0208) Val Loss: 0.2604892027242102\n",
      "Epoch:  1 Val Acc:  tensor(0.0212) Val Loss: 0.2759715830871814\n",
      "Epoch:  1 Val Acc:  tensor(0.0247) Val Loss: 0.29200806998481316\n",
      "Epoch:  1 Val Acc:  tensor(0.0249) Val Loss: 0.30850756394999107\n",
      "Epoch:  1 Val Acc:  tensor(0.0250) Val Loss: 0.32438237766802536\n",
      "Epoch:  1 Val Acc:  tensor(0.0291) Val Loss: 0.33964719155895395\n",
      "Epoch:  1 Val Acc:  tensor(0.0278) Val Loss: 0.3559566196833273\n",
      "Epoch:  1 Val Acc:  tensor(0.0314) Val Loss: 0.3718769287428475\n",
      "Epoch:  1 Val Acc:  tensor(0.0301) Val Loss: 0.38909266294182027\n",
      "Epoch:  1 Val Acc:  tensor(0.0300) Val Loss: 0.4047433541301539\n",
      "Epoch:  1 Val Acc:  tensor(0.0288) Val Loss: 0.42053765851735164\n",
      "Epoch:  1 Val Acc:  tensor(0.0278) Val Loss: 0.4366912714882042\n",
      "Epoch:  1 Val Acc:  tensor(0.0278) Val Loss: 0.45305644604643036\n",
      "Epoch:  1 Val Acc:  tensor(0.0268) Val Loss: 0.4695357315440595\n",
      "Epoch:  1 Val Acc:  tensor(0.0269) Val Loss: 0.48566928471902476\n",
      "Epoch:  1 Val Acc:  tensor(0.0260) Val Loss: 0.502027312159085\n",
      "Epoch:  1 Val Acc:  tensor(0.0252) Val Loss: 0.5192965790346095\n",
      "Epoch:  1 Val Acc:  tensor(0.0261) Val Loss: 0.5352210817228252\n",
      "Epoch:  1 Val Acc:  tensor(0.0261) Val Loss: 0.5516569152077795\n",
      "Epoch:  1 Val Acc:  tensor(0.0254) Val Loss: 0.5678003604874411\n",
      "Epoch:  1 Val Acc:  tensor(0.0255) Val Loss: 0.5834106002923654\n",
      "Epoch:  1 Val Acc:  tensor(0.0248) Val Loss: 0.5997822039934165\n",
      "Epoch:  1 Val Acc:  tensor(0.0241) Val Loss: 0.6159365113697125\n",
      "Epoch:  1 Val Acc:  tensor(0.0242) Val Loss: 0.6321548853536976\n",
      "Epoch:  1 Val Acc:  tensor(0.0236) Val Loss: 0.6488799396123269\n",
      "Epoch:  1 Val Acc:  tensor(0.0237) Val Loss: 0.6657367169630392\n",
      "Epoch:  1 Val Acc:  tensor(0.0231) Val Loss: 0.6822334786331699\n",
      "Epoch:  1 Val Acc:  tensor(0.0226) Val Loss: 0.6982607750838247\n",
      "Epoch:  1 Val Acc:  tensor(0.0234) Val Loss: 0.7147871224145925\n",
      "Epoch:  1 Val Acc:  tensor(0.0228) Val Loss: 0.7311725960938196\n",
      "Epoch:  1 Val Acc:  tensor(0.0223) Val Loss: 0.7480874623635876\n",
      "Epoch:  1 Val Acc:  tensor(0.0225) Val Loss: 0.7641363851017825\n",
      "Epoch:  1 Val Acc:  tensor(0.0231) Val Loss: 0.7803789563052101\n",
      "Epoch:  1 Val Acc:  tensor(0.0227) Val Loss: 0.7967878348927081\n",
      "Epoch:  1 Val Acc:  tensor(0.0222) Val Loss: 0.813068509555135\n",
      "Epoch:  1 Val Acc:  tensor(0.0218) Val Loss: 0.829500419558681\n",
      "Epoch:  1 Val Acc:  tensor(0.0219) Val Loss: 0.8452875441924701\n",
      "Epoch:  1 Val Acc:  tensor(0.0220) Val Loss: 0.8620845736659525\n",
      "Epoch:  1 Val Acc:  tensor(0.0221) Val Loss: 0.8789659434851584\n",
      "Epoch:  1 Val Acc:  tensor(0.0217) Val Loss: 0.8955394904423123\n",
      "Epoch:  1 Val Acc:  tensor(0.0213) Val Loss: 0.9119392057788689\n",
      "Epoch:  1 Val Acc:  tensor(0.0214) Val Loss: 0.92839750500233\n",
      "Epoch:  1 Val Acc:  tensor(0.0216) Val Loss: 0.9445179895756363\n",
      "Epoch:  1 Val Acc:  tensor(0.0212) Val Loss: 0.9613446536626199\n",
      "Epoch:  1 Val Acc:  tensor(0.0208) Val Loss: 0.9770874088707986\n",
      "Epoch:  1 Val Acc:  tensor(0.0205) Val Loss: 0.9928407814112906\n",
      "Epoch:  1 Val Acc:  tensor(0.0206) Val Loss: 1.0097307451777584\n",
      "Epoch:  1 Val Acc:  tensor(0.0207) Val Loss: 1.0259460061221974\n",
      "Epoch:  1 Val Acc:  tensor(0.0204) Val Loss: 1.0432182373656067\n",
      "Epoch:  1 Val Acc:  tensor(0.0205) Val Loss: 1.0597948357179592\n",
      "Epoch:  1 Val Acc:  tensor(0.0206) Val Loss: 1.0763046768681632\n",
      "Epoch:  1 Val Acc:  tensor(0.0207) Val Loss: 1.0920343924837874\n",
      "Epoch:  1 Val Acc:  tensor(0.0208) Val Loss: 1.1083128570150513\n",
      "Epoch:  1 Val Acc:  tensor(0.0205) Val Loss: 1.1238747694646452\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 1.1397684753621034\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 1.1560888888718057\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 1.1725520851947508\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 1.189224865046744\n",
      "Epoch:  1 Val Acc:  tensor(0.0199) Val Loss: 1.205522908910599\n",
      "Epoch:  1 Val Acc:  tensor(0.0196) Val Loss: 1.2214623331570353\n",
      "Epoch:  1 Val Acc:  tensor(0.0194) Val Loss: 1.2376300717487987\n",
      "Epoch:  1 Val Acc:  tensor(0.0191) Val Loss: 1.2541571298026313\n",
      "Epoch:  1 Val Acc:  tensor(0.0189) Val Loss: 1.2702634053538506\n",
      "Epoch:  1 Val Acc:  tensor(0.0190) Val Loss: 1.287146580989823\n",
      "Epoch:  1 Val Acc:  tensor(0.0188) Val Loss: 1.303699564117896\n",
      "Epoch:  1 Val Acc:  tensor(0.0195) Val Loss: 1.31992714305341\n",
      "Epoch:  1 Val Acc:  tensor(0.0193) Val Loss: 1.336111625337782\n",
      "Epoch:  1 Val Acc:  tensor(0.0194) Val Loss: 1.352026691001631\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 1.3680272428708384\n",
      "Epoch:  1 Val Acc:  tensor(0.0203) Val Loss: 1.3844018163789815\n",
      "Epoch:  1 Val Acc:  tensor(0.0203) Val Loss: 1.4005752389421935\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 1.4171681313460318\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 1.4333320262314249\n",
      "Epoch:  1 Val Acc:  tensor(0.0203) Val Loss: 1.449349628201909\n",
      "Epoch:  1 Val Acc:  tensor(0.0207) Val Loss: 1.4654891790092672\n",
      "Epoch:  1 Val Acc:  tensor(0.0205) Val Loss: 1.4818203548968065\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 1.498986200688003\n",
      "Epoch:  1 Val Acc:  tensor(0.0203) Val Loss: 1.5148892747132043\n",
      "Epoch:  1 Val Acc:  tensor(0.0210) Val Loss: 1.5302382512690904\n",
      "Epoch:  1 Val Acc:  tensor(0.0208) Val Loss: 1.5470393528956423\n",
      "Epoch:  1 Val Acc:  tensor(0.0205) Val Loss: 1.5631147264980998\n",
      "Epoch:  1 Val Acc:  tensor(0.0206) Val Loss: 1.5790544208918234\n",
      "Epoch:  1 Val Acc:  tensor(0.0204) Val Loss: 1.5953936250490834\n",
      "Epoch:  1 Val Acc:  tensor(0.0210) Val Loss: 1.6107509943015674\n",
      "Epoch:  1 Val Acc:  tensor(0.0211) Val Loss: 1.6275218031705558\n",
      "Epoch:  1 Val Acc:  tensor(0.0212) Val Loss: 1.643530602690838\n",
      "Epoch:  1 Val Acc:  tensor(0.0212) Val Loss: 1.6596107773001203\n",
      "Epoch:  1 Val Acc:  tensor(0.0210) Val Loss: 1.6752533930789382\n",
      "Epoch:  1 Val Acc:  tensor(0.0211) Val Loss: 1.6915579639913465\n",
      "Epoch:  1 Val Acc:  tensor(0.0212) Val Loss: 1.7075831808518094\n",
      "Epoch:  1 Val Acc:  tensor(0.0210) Val Loss: 1.7242427688134487\n",
      "Epoch:  1 Val Acc:  tensor(0.0210) Val Loss: 1.7406173260039703\n",
      "Epoch:  1 Val Acc:  tensor(0.0211) Val Loss: 1.756229924611719\n",
      "Epoch:  1 Val Acc:  tensor(0.0209) Val Loss: 1.7722974820735338\n",
      "Epoch:  1 Val Acc:  tensor(0.0210) Val Loss: 1.7883605721332274\n",
      "Epoch:  1 Val Acc:  tensor(0.0208) Val Loss: 1.8041674084536476\n",
      "Epoch:  1 Val Acc:  tensor(0.0206) Val Loss: 1.8206550975262892\n",
      "Epoch:  1 Val Acc:  tensor(0.0204) Val Loss: 1.837027319483884\n",
      "Epoch:  1 Val Acc:  tensor(0.0205) Val Loss: 1.8530413170731113\n",
      "Epoch:  1 Val Acc:  tensor(0.0208) Val Loss: 1.8687806564592138\n",
      "Epoch:  1 Val Acc:  tensor(0.0208) Val Loss: 1.8858328336998538\n",
      "Epoch:  1 Val Acc:  tensor(0.0207) Val Loss: 1.902235803495342\n",
      "Epoch:  1 Val Acc:  tensor(0.0207) Val Loss: 1.9183923228158697\n",
      "Epoch:  1 Val Acc:  tensor(0.0205) Val Loss: 1.9345446231247354\n",
      "Epoch:  1 Val Acc:  tensor(0.0204) Val Loss: 1.9518635118868868\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 1.9689527011189625\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 1.9852744345429278\n",
      "Epoch:  1 Val Acc:  tensor(0.0199) Val Loss: 2.0016194441472623\n",
      "Epoch:  1 Val Acc:  tensor(0.0199) Val Loss: 2.0178246479977218\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.0340922830675945\n",
      "Epoch:  1 Val Acc:  tensor(0.0203) Val Loss: 2.050337361745508\n",
      "Epoch:  1 Val Acc:  tensor(0.0203) Val Loss: 2.066455239125531\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 2.08248688331575\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.0993907895831554\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.1157556559196444\n",
      "Epoch:  1 Val Acc:  tensor(0.0199) Val Loss: 2.131959365801213\n",
      "Epoch:  1 Val Acc:  tensor(0.0198) Val Loss: 2.14866175669681\n",
      "Epoch:  1 Val Acc:  tensor(0.0198) Val Loss: 2.1648356415926275\n",
      "Epoch:  1 Val Acc:  tensor(0.0197) Val Loss: 2.1825031073827708\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.199117065835815\n",
      "Epoch:  1 Val Acc:  tensor(0.0198) Val Loss: 2.2158283262651683\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.23213260708653\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.2485196273136503\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 2.264986085347803\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 2.2816687119777663\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.2985635021340256\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.314680284420347\n",
      "Epoch:  1 Val Acc:  tensor(0.0198) Val Loss: 2.33121069302577\n",
      "Epoch:  1 Val Acc:  tensor(0.0199) Val Loss: 2.347387890398729\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.363743945219671\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.3790491597280754\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.3959806681585856\n",
      "Epoch:  1 Val Acc:  tensor(0.0199) Val Loss: 2.412740323026824\n",
      "Epoch:  1 Val Acc:  tensor(0.0199) Val Loss: 2.429228280433684\n",
      "Epoch:  1 Val Acc:  tensor(0.0198) Val Loss: 2.4460384673492084\n",
      "Epoch:  1 Val Acc:  tensor(0.0197) Val Loss: 2.4620669622385005\n",
      "Epoch:  1 Val Acc:  tensor(0.0199) Val Loss: 2.4787321525834813\n",
      "Epoch:  1 Val Acc:  tensor(0.0198) Val Loss: 2.495727283419765\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.5123205239328597\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.528131572012666\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.544233599543118\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.5602157542007506\n",
      "Epoch:  1 Val Acc:  tensor(0.0199) Val Loss: 2.576889536679924\n",
      "Epoch:  1 Val Acc:  tensor(0.0203) Val Loss: 2.5927136479221824\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.6093802161996353\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.6263527978962364\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 2.642616181319204\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.65916573049451\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.6749487503399867\n",
      "Epoch:  1 Val Acc:  tensor(0.0200) Val Loss: 2.6913042920623895\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.70796751341439\n",
      "Epoch:  1 Val Acc:  tensor(0.0203) Val Loss: 2.7244524393698106\n",
      "Epoch:  1 Val Acc:  tensor(0.0202) Val Loss: 2.7400167668273694\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.756493813184731\n",
      "Epoch:  1 Val Acc:  tensor(0.0201) Val Loss: 2.7733399804554058\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5136/4124712075.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mval_total_correct\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \"\"\"\n\u001b[0;32m    231\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2975\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2977\u001b[1;33m     \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neural_net=CNN()\n",
    "\n",
    "use_cuda=True\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    neural_net.cuda()\n",
    "    optimiser= optim.SGD(neural_net.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    epoch=0\n",
    "    max_epoch=3\n",
    "    end=False\n",
    "    myloss=loss_cell()\n",
    "    \n",
    "    while epoch< max_epoch and not end:\n",
    "        epoch+=1\n",
    "        total_loss=0\n",
    "        total_correct=0\n",
    "        total_val=0\n",
    "        total_train=0\n",
    "        \n",
    "        for dataset in (train_loader):\n",
    "            images, lables=dataset\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                images=images.cuda()\n",
    "                lables=lables.cuda()\n",
    "            pred=neural_net(images)\n",
    "            pred=F.softmax(pred)\n",
    "            loss=myloss(pred, lables)\n",
    "            \n",
    "            total_loss+=loss.item()\n",
    "            total_train+=len(pred)\n",
    "            \n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            total_correct +=pred.argmax(dim=1).eq(lables).sum()\n",
    "            train_acc= (total_correct*1.0)/total_train\n",
    "            \n",
    "            print(\"Epoch: \", epoch, \"Training accu:\", train_acc, \"Train Loss:\", total_loss*1.0/len(train_loader))\n",
    "            \n",
    "            if total_correct*1.0/total_train>=0.98:\n",
    "                end=True\n",
    "            total_loss=0\n",
    "            val_total_correct=0\n",
    "            \n",
    "            for batch in (val_loader):\n",
    "                images, lables=batch\n",
    "                \n",
    "                if use_cuda  and torch.cuda.is_available():\n",
    "                    images=images.cuda()\n",
    "                    lables=lables.cuda()\n",
    "                pred=neural_net(images)\n",
    "                \n",
    "                loss=F.cross_entropy(pred, lables)\n",
    "                total_loss+=loss.item()\n",
    "                total_val+=len(pred)\n",
    "                \n",
    "                val_total_correct+=pred.argmax(dim=1).eq(lables).sum()\n",
    "                val_acc= (val_total_correct*1.0)/total_val\n",
    "                \n",
    "                print(\"Epoch: \", epoch,\"Val Acc: \", val_acc,\"Val Loss:\", total_loss*1.0/len(val_loader))\n",
    "                \n",
    "            torch.cuda.empty_cache()\n",
    "else:\n",
    "    neural_net.cpu()\n",
    "    optimiser= optim.SGD(neural_net.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    epoch=0\n",
    "    max_epoch=10\n",
    "    end=False\n",
    "    myloss=loss_cell()\n",
    "    \n",
    "    while epoch< max_epoch and not end:\n",
    "        epoch+=1\n",
    "        total_loss=0\n",
    "        total_correct=0\n",
    "        total_val=0\n",
    "        total_train=0\n",
    "        \n",
    "        for dataset in (train_loader):\n",
    "            images, lables=dataset\n",
    "         \n",
    "            images=images.cpu()\n",
    "            lables=lables.cpu()\n",
    "            pred=neural_net(images)\n",
    "            pred=F.softmax(pred)\n",
    "            loss=myloss(pred, lables)\n",
    "            \n",
    "            total_loss+=loss.item()\n",
    "            total_train+=len(pred)\n",
    "            \n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            total_correct +=pred.argmax(dim=1).eq(lables).sum()\n",
    "            \n",
    "            train_acc= (total_correct*1.0)/total_train\n",
    "            \n",
    "            print(\"Epoch: \", epoch, \"Training accu:\", train_acc, \"Train Loss:\", total_loss*1.0/len(train_loader))\n",
    "            \n",
    "            if total_correct*1.0/total_train>=0.98:\n",
    "                end=True\n",
    "            total_loss=0\n",
    "            val_total_correct=0\n",
    "            \n",
    "            for batch in (val_loader):\n",
    "                images, lables=batch\n",
    "               \n",
    "                images=images.cpu()\n",
    "                lables=lables.cpu()\n",
    "                pred=neural_net(images)\n",
    "                \n",
    "                loss=F.cross_entropy(pred, lables)\n",
    "                total_loss+=loss.item()\n",
    "                total_val+=len(pred)\n",
    "                \n",
    "                val_total_correct+=pred.argmax(dim=1).eq(lables).sum()\n",
    "                val_acc= (val_total_correct*1.0)/total_val\n",
    "                \n",
    "                print(\"Epoch: \", epoch,\"Val Acc: \", val_acc,\"Val Loss:\", total_loss*1.0/len(val_loader))\n",
    "                \n",
    "        \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: tensor(0.0278)\n",
      "Test Acc: tensor(0.0139)\n",
      "Test Acc: tensor(0.0278)\n",
      "Test Acc: tensor(0.0347)\n",
      "Test Acc: tensor(0.0333)\n",
      "Test Acc: tensor(0.0324)\n",
      "Test Acc: tensor(0.0278)\n",
      "Test Acc: tensor(0.0278)\n",
      "Test Acc: tensor(0.0278)\n",
      "Test Acc: tensor(0.0250)\n",
      "Test Acc: tensor(0.0253)\n",
      "Test Acc: tensor(0.0255)\n",
      "Test Acc: tensor(0.0235)\n",
      "Test Acc: tensor(0.0218)\n",
      "Test Acc: tensor(0.0222)\n",
      "Test Acc: tensor(0.0208)\n",
      "Test Acc: tensor(0.0229)\n",
      "Test Acc: tensor(0.0247)\n",
      "Test Acc: tensor(0.0234)\n",
      "Test Acc: tensor(0.0236)\n",
      "Test Acc: tensor(0.0238)\n",
      "Test Acc: tensor(0.0253)\n",
      "Test Acc: tensor(0.0266)\n",
      "Test Acc: tensor(0.0266)\n",
      "Test Acc: tensor(0.0256)\n",
      "Test Acc: tensor(0.0246)\n",
      "Test Acc: tensor(0.0257)\n",
      "Test Acc: tensor(0.0248)\n",
      "Test Acc: tensor(0.0249)\n",
      "Test Acc: tensor(0.0259)\n",
      "Test Acc: tensor(0.0260)\n",
      "Test Acc: tensor(0.0252)\n",
      "Test Acc: tensor(0.0253)\n",
      "Test Acc: tensor(0.0245)\n",
      "Test Acc: tensor(0.0246)\n",
      "Test Acc: tensor(0.0247)\n",
      "Test Acc: tensor(0.0248)\n",
      "Test Acc: tensor(0.0256)\n",
      "Test Acc: tensor(0.0278)\n",
      "Test Acc: tensor(0.0278)\n",
      "Test Acc: tensor(0.0271)\n",
      "Test Acc: tensor(0.0265)\n",
      "Test Acc: tensor(0.0265)\n",
      "Test Acc: tensor(0.0259)\n",
      "Test Acc: tensor(0.0259)\n",
      "Test Acc: tensor(0.0254)\n",
      "Test Acc: tensor(0.0248)\n",
      "Test Acc: tensor(0.0249)\n",
      "Test Acc: tensor(0.0266)\n",
      "Test Acc: tensor(0.0267)\n",
      "Test Acc: tensor(0.0267)\n",
      "Test Acc: tensor(0.0267)\n",
      "Test Acc: tensor(0.0262)\n",
      "Test Acc: tensor(0.0267)\n",
      "Test Acc: tensor(0.0268)\n",
      "Test Acc: tensor(0.0268)\n",
      "Test Acc: tensor(0.0263)\n",
      "Test Acc: tensor(0.0259)\n",
      "Test Acc: tensor(0.0259)\n",
      "Test Acc: tensor(0.0259)\n",
      "Test Acc: tensor(0.0255)\n",
      "Test Acc: tensor(0.0251)\n",
      "Test Acc: tensor(0.0251)\n",
      "Test Acc: tensor(0.0247)\n",
      "Test Acc: tensor(0.0244)\n",
      "Test Acc: tensor(0.0240)\n",
      "Test Acc: tensor(0.0236)\n",
      "Test Acc: tensor(0.0237)\n",
      "Test Acc: tensor(0.0233)\n",
      "Test Acc: tensor(0.0238)\n",
      "Test Acc: tensor(0.0235)\n",
      "Test Acc: tensor(0.0231)\n",
      "Test Acc: tensor(0.0240)\n",
      "Test Acc: tensor(0.0236)\n",
      "Test Acc: tensor(0.0233)\n",
      "Test Acc: tensor(0.0238)\n",
      "Test Acc: tensor(0.0238)\n",
      "Test Acc: tensor(0.0242)\n",
      "Test Acc: tensor(0.0243)\n",
      "Test Acc: tensor(0.0250)\n",
      "Test Acc: tensor(0.0250)\n",
      "Test Acc: tensor(0.0254)\n",
      "Test Acc: tensor(0.0251)\n",
      "Test Acc: tensor(0.0255)\n",
      "Test Acc: tensor(0.0255)\n",
      "Test Acc: tensor(0.0255)\n",
      "Test Acc: tensor(0.0255)\n",
      "Test Acc: tensor(0.0253)\n",
      "Test Acc: tensor(0.0250)\n",
      "Test Acc: tensor(0.0250)\n",
      "Test Acc: tensor(0.0250)\n",
      "Test Acc: tensor(0.0248)\n",
      "Test Acc: tensor(0.0251)\n",
      "Test Acc: tensor(0.0248)\n",
      "Test Acc: tensor(0.0254)\n",
      "Test Acc: tensor(0.0252)\n",
      "Test Acc: tensor(0.0252)\n",
      "Test Acc: tensor(0.0249)\n",
      "Test Acc: tensor(0.0247)\n",
      "Test Acc: tensor(0.0244)\n",
      "Test Acc: tensor(0.0245)\n",
      "Test Acc: tensor(0.0248)\n",
      "Test Acc: tensor(0.0245)\n",
      "Test Acc: tensor(0.0243)\n",
      "Test Acc: tensor(0.0241)\n",
      "Test Acc: tensor(0.0238)\n",
      "Test Acc: tensor(0.0236)\n",
      "Test Acc: tensor(0.0234)\n",
      "Test Acc: tensor(0.0232)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8680/2615484163.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m  \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \"\"\"\n\u001b[0;32m    231\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ekole\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2975\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2977\u001b[1;33m     \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_total_correct=0\n",
    "total_test=0\n",
    "\n",
    "x=0\n",
    "\n",
    "for batch  in (test_loader):\n",
    "    images, lables=batch\n",
    "    \n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        images=images.cuda()\n",
    "        lables=lables.cuda()\n",
    "    else:\n",
    "        images=images.cpu()\n",
    "        lables=lables.cpu()\n",
    "    pred= neural_net(images)\n",
    "    total_test+=len(pred)\n",
    "    \n",
    "    x+=1\n",
    "    \n",
    "    test_total_correct+=pred.argmax(dim=1).eq(lables).sum()\n",
    "    \n",
    "    print(\"Test Acc:\", test_total_correct*1.0/total_test)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path=\"model.pth\"\n",
    "\n",
    "torch.save(neural_net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_machine=True\n",
    "\n",
    "def load_model(path):\n",
    "    if local_machine:\n",
    "        checkpoint= torch.load(path, map_location='cpu')\n",
    "    else:\n",
    "        checkpoint= torch.load(path)\n",
    "    model=neural_net\n",
    "    \n",
    "    for params in model.parameters():\n",
    "        params.requires_grad= False\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= load_model(\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def process_image(image):\n",
    "    img_transforms=transforms.Compose(\n",
    "        [\n",
    "        transforms.Resize((48,48)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "    image=img_transforms(Image.open(image))\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig,ax=plt.subplots()\n",
    "        \n",
    "    image=image.numpy().transpose((1,2,0))\n",
    "        \n",
    "    mean= np.array([0.5])\n",
    "    std=np.array([0.5])\n",
    "        \n",
    "    image= std*image+mean\n",
    "        \n",
    "    ax.display_img(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= process_image('./EnglishFnt/English/Fnt/Sample001/img001-00007.png')\n",
    "display_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(image_path, neural_net):\n",
    "    image_data= process_image(image_path)\n",
    "    model=load_model(path)\n",
    "    model_p= model.eval()\n",
    "    inputs= Variable(image_data.unsqueeze(0))\n",
    "    output=model_p(inputs)\n",
    "    \n",
    "    return output\n",
    "     \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c665350156eabd990feb1e968b8d1a10f489d6206cd46e13f7f6c15c0612df4c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ekole': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
